\documentclass{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

% ===== PACKAGES =====
\usepackage{amsmath,amssymb}
\usepackage{color}
\usepackage{subfigure}
\usepackage{mdframed}
\usepackage{changepage}
\newmdenv[
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep
]{siderules}
\renewcommand{\abstractname}{}

% ===== VARIABLES =====
\def \R{\mathbb{R}}
\def \Pr{\mathbb{P}}
\def \D{{\rm D}}
\def \N{{\rm N}}
\def \xx{{\boldsymbol{\rm x}}}
\def \y{{\rm y}}




% ===== HEADER BOX =====
\newcommand{\lecture}[2]{
\pagestyle{myheadings}
\thispagestyle{plain}
\newpage
\noindent
\begin{center}
\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal line
\rule{\textwidth}{0.4pt}\\[1\baselineskip] % Thin horizontal line
\vbox{\vspace{2mm}
\hbox to 6.28in { {\bf CS 760: Machine Learning} \hfill Spring 2024 }
\vspace{4mm}
\hbox to 6.28in { {\Large \hfill #1  \hfill} }
\vspace{4mm}
\hbox to 6.28in { {\scshape Authors:}  #2 \hfill }}
\vspace{-2mm}
\rule{\textwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal line
\rule{\textwidth}{1.6pt}\\[\baselineskip] % Thick horizontal line
\end{center}
\vspace*{4mm}
}

% ===== Jed's Defined Stuff ======
\DeclareMathOperator*{\argmin}{arg\!\min}
\DeclareMathOperator*{\argmax}{arg\!\max}
\usepackage{siunitx}
\usepackage{enumitem} % used to make alphabetical lists instead of numbered ones
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{caption}

% =============== DOCUMENT ===============
\begin{document}
\lecture{Homework 6: Frequentists vs Bayesians}{Jed Pulley}

\begin{center}
{\Large {\sf \underline{\textbf{DO NOT POLLUTE!}} AVOID PRINTING, OR PRINT 2-SIDED MULTIPAGE.}}
\end{center}

\section*{Problem 6.1. Frequentist (MLE)}
To find the MLE of $p*$, we first start with the likelihood function:
\[P(p*) = \prod^n_{i=1} (p^{\sf{x}_i}(1-p)^{1 - \sf{x}_i})\]

Then we take the log of the likelihood function:
\[ log(P(p^*)) = logp \sum_{i=1}^{n} \sf{x}_i + log (1 - p) \sum_{i=1}^{n}(1 - \sf{x}_i) \]

Using our optimization 101 technique, we get the derivative and set it equal to zero:
\[ p_{MLE} = \frac{1}{n} \sum_{i=1}^{n} \sf{x}_i \]

Which we recognize to just be the mean.


\section*{Problem 6.2}

\section*{Problem 6.3}
  \begin{enumerate}[label=(\alph*)]
    \item 
    \item 
\end{enumerate}

\section*{Problem 6.4}
  \begin{enumerate}[label=(\alph*)]
    \item 
    \item 
\end{enumerate}

\section*{Problem 6.5}

\end{document} 
































